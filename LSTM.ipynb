{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "    X, y = [], []\n",
    "    columns = ['Pelvis Accel Sensor X,mG', 'Pelvis Accel Sensor Y,mG',\n",
    "       'Pelvis Accel Sensor Z,mG', 'Pelvis Rot X,', 'Pelvis Rot Y,',    \n",
    "       'Pelvis Rot Z,']\n",
    "    # Iterate through each subdirectory (falls and nonFalls)\n",
    "    for subdir in os.listdir(directory):\n",
    "        # Ignore any files in the directory\n",
    "        if not os.path.isdir(os.path.join(directory, subdir)):\n",
    "            continue\n",
    "        # Iterate through each file in the subdirectory\n",
    "        for file in os.listdir(os.path.join(directory, subdir)):\n",
    "        \n",
    "            filepath = os.path.join(directory, subdir, file)\n",
    "            # Load the data from each CSV file\n",
    "            data = pd.read_csv(filepath,usecols=columns)\n",
    "            # Append data and labels to X and y lists\n",
    "            X.append(data.values)  # Assuming all columns are features\n",
    "            # Assign label based on subdirectory\n",
    "            y.append(1 if subdir == 'fall' else 0)  # Assuming 'falls' is class 1, and 'nonFalls' is class 0\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy,class_weights):\n",
    "    verbose, epochs, batch_size = 1, 6, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(n_timesteps,n_features), return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','recall','precision'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose,class_weight = class_weights)\n",
    "    preds = model.predict(testX, batch_size=batch_size, verbose=1)\n",
    "    return np.argmax(preds,axis=1)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 274ms/step - accuracy: 0.5420 - loss: 0.6986 - precision: 0.5339 - recall: 0.5938\n",
      "Epoch 2/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - accuracy: 0.6546 - loss: 0.6681 - precision: 0.6537 - recall: 0.6366\n",
      "Epoch 3/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 319ms/step - accuracy: 0.6543 - loss: 0.6490 - precision: 0.6768 - recall: 0.5647\n",
      "Epoch 4/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 320ms/step - accuracy: 0.7119 - loss: 0.6140 - precision: 0.7164 - recall: 0.7035\n",
      "Epoch 5/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 343ms/step - accuracy: 0.4771 - loss: 0.7145 - precision: 0.4879 - recall: 0.5248\n",
      "Epoch 6/6\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - accuracy: 0.7774 - loss: 0.6401 - precision: 0.7699 - recall: 0.7809\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step\n",
      "Accuracy:  0.8324022346368715\n",
      "Precision:  0.525\n",
      "Recall:  0.65625\n",
      "F1:  0.5833333333333334\n",
      "[[256  38]\n",
      " [ 22  42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Load training data\n",
    "trainX, trainy = load_dataset('./3S/train')\n",
    "\n",
    "class_weights = compute_class_weight(class_weight = \"balanced\",\n",
    "                                    classes = np.unique(trainy),\n",
    "                                    y = trainy)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "trainy = to_categorical(trainy)\n",
    "\n",
    "\n",
    "# Load testing data\n",
    "testX, testy = load_dataset('./3S/test')\n",
    "testy = to_categorical(testy)\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 6))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 6))\n",
    "\n",
    "\n",
    "true_labels = [np.argmax(label) for label in testy]\n",
    "preds = evaluate_model(trainX, trainy, testX, testy,class_weights)\n",
    "\n",
    "print(\"Accuracy: \",  accuracy_score(true_labels, preds))\n",
    "print(\"Precision: \", precision_score(true_labels, preds))\n",
    "print(\"Recall: \", recall_score(true_labels, preds))\n",
    "print(\"F1: \", f1_score(true_labels, preds))\n",
    "print(confusion_matrix(true_labels,preds))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
