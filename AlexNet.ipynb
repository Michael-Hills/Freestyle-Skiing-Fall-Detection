{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation\n",
    "\n",
    "Augment images to be in line with the pre-trained network format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=227),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=227),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# load all images in train and test sets\n",
    "dataset = 'Images2'\n",
    "\n",
    "trainDirectory = os.path.join(dataset, 'Train')\n",
    "testDirectory = os.path.join(dataset, 'Test')\n",
    "batchSize = 32\n",
    "\n",
    "num_classes = len(os.listdir(trainDirectory))\n",
    "\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=trainDirectory, transform=image_transforms['train']),\n",
    "    'test': datasets.ImageFolder(root=testDirectory, transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "\n",
    "idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
    "\n",
    "\n",
    "train_data_size = len(data['train'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "train_data_loader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
    "test_data_loader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCELoss_class_weighted(weights):\n",
    "\n",
    "    \"\"\"Calculate the binary cross entropy with weights \"\"\"\n",
    "\n",
    "    def loss(input, target):\n",
    "        input = torch.clamp(input,min=1e-7,max=1-1e-7)\n",
    "        bce = - weights[1] * target * torch.log(input) - (1 - target) * weights[0] * torch.log(1 - input)\n",
    "        return torch.mean(bce)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained weights\n",
    "alexnet = models.alexnet(weights='IMAGENET1K_V1')\n",
    "\n",
    "# If both are commented out all layers are retrained\n",
    "\n",
    "\"\"\"\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False       \"\"\"                # Retrain only last\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for name, param in alexnet.named_parameters():\n",
    "    if 'features' in name:                              # Retrain fully connected layers\n",
    "        param.requires_grad = False\"\"\"\n",
    "\n",
    "\n",
    "# alter network\n",
    "num_features = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "loss_func = BCELoss_class_weighted([1,2.8])\n",
    "optimizer = optim.Adam(alexnet.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def predict(model,confusion=True):\n",
    "\n",
    "    \"\"\"Function to predict the test set and print performance metrics\"\"\"\n",
    "\n",
    "    test_acc = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "        \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(test_data_loader):\n",
    "\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            predictions = (outputs >= 0.50).float() #torch.round(outputs)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "          \n",
    "    avg_test_acc = test_acc/test_data_size\n",
    "    \n",
    "\n",
    "    print(\"Test Accuracy: \", avg_test_acc)\n",
    "    \n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "\n",
    "    print(\"Test Recall: \",conf_matrix[1][1] / (conf_matrix[1][1] + conf_matrix[1][0]) )\n",
    "    print(\"Test Precision: \",conf_matrix[1][1] / (conf_matrix[1][1] + conf_matrix[0][1]))\n",
    "    if confusion == True:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, loss_criterion, optimizer, epochs=20):  \n",
    "\n",
    "    \"\"\"Function to train and evaluate the model\"\"\"\n",
    "\n",
    "\n",
    "  \n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        \n",
    "        # Training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loss and accuracy\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "    \n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(tqdm(train_data_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            labels = labels.unsqueeze(1)\n",
    "            labels = labels.float()\n",
    "            \n",
    "            # clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass to calculate outputs\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute loss for the batch \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            predictions =   (outputs >= 0.50).float() #torch.round(outputs)\n",
    "        \n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            \n",
    "            # calculate training accuracy\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            \n",
    "\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "\n",
    "        history.append([avg_train_loss, avg_train_acc])\n",
    "                \n",
    "        epoch_end = time.time()\n",
    "    \n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch+1, avg_train_loss, avg_train_acc*100, epoch_end-epoch_start))\n",
    "        predict(model,confusion=True)\n",
    "     \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "trained_model, history = train_and_validate(alexnet, loss_func, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
